{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from scipy.stats import mstats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0     1     2     3     4     5     6     7   8   9  ...  31  32  33  34  \\\n",
      "0  48.0  32.0  47.0  64.0  34.0  14.0  14.0  15.0  42  61 ...  42  62  33  33   \n",
      "1  34.0  21.0  82.0  48.0  29.0  11.0  14.0  14.0  34  31 ...  47  48  61  63   \n",
      "2  45.0  34.0  54.0  65.0  43.0  13.0  11.0   9.0  42  61 ...  42  62  33  33   \n",
      "3  69.0  57.0  47.0  85.0  47.0   6.0  11.0  10.0  37  32 ...  52  61  62  64   \n",
      "4  36.0  30.0  50.0  59.0  35.0   6.0  13.0  13.0  37  32 ...  52  61  62  64   \n",
      "\n",
      "   35  36  37  38  39  40  \n",
      "0  41  11  13  14   7   6  \n",
      "1  58   7   5  14  13  12  \n",
      "2  41  11  13  14   7   6  \n",
      "3  60   8   6  15  14  13  \n",
      "4  60   8   6  15  14  13  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    1\n",
      "4    1\n",
      "Name: 41, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Getting the data from csv file to pandas dataframe\n",
    "df = pd.read_csv('data.csv', header=None)\n",
    "\n",
    "# Reading the target variable into y and removing it from original dataframe\n",
    "y = df[41]\n",
    "del(df[41])\n",
    "\n",
    "print(df.head(5))\n",
    "print(y.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Check for missing values </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20854.000000</td>\n",
       "      <td>20854.000000</td>\n",
       "      <td>20854.000000</td>\n",
       "      <td>20854.000000</td>\n",
       "      <td>20854.000000</td>\n",
       "      <td>20854.000000</td>\n",
       "      <td>20854.000000</td>\n",
       "      <td>20854.000000</td>\n",
       "      <td>20854.000000</td>\n",
       "      <td>20854.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20854.000000</td>\n",
       "      <td>20854.000000</td>\n",
       "      <td>20854.000000</td>\n",
       "      <td>20854.000000</td>\n",
       "      <td>20854.000000</td>\n",
       "      <td>20854.000000</td>\n",
       "      <td>20854.000000</td>\n",
       "      <td>20854.000000</td>\n",
       "      <td>20854.000000</td>\n",
       "      <td>20854.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>55.946885</td>\n",
       "      <td>51.186513</td>\n",
       "      <td>58.790715</td>\n",
       "      <td>63.548063</td>\n",
       "      <td>50.059329</td>\n",
       "      <td>17.920492</td>\n",
       "      <td>13.673587</td>\n",
       "      <td>14.056053</td>\n",
       "      <td>36.904766</td>\n",
       "      <td>39.794428</td>\n",
       "      <td>...</td>\n",
       "      <td>45.481538</td>\n",
       "      <td>54.945478</td>\n",
       "      <td>42.496643</td>\n",
       "      <td>38.513139</td>\n",
       "      <td>38.419344</td>\n",
       "      <td>14.767287</td>\n",
       "      <td>13.279179</td>\n",
       "      <td>20.379591</td>\n",
       "      <td>17.112544</td>\n",
       "      <td>15.774911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.846184</td>\n",
       "      <td>17.353144</td>\n",
       "      <td>13.560364</td>\n",
       "      <td>12.541247</td>\n",
       "      <td>16.577858</td>\n",
       "      <td>18.497045</td>\n",
       "      <td>11.288914</td>\n",
       "      <td>12.213878</td>\n",
       "      <td>12.595262</td>\n",
       "      <td>14.124485</td>\n",
       "      <td>...</td>\n",
       "      <td>7.814612</td>\n",
       "      <td>8.086104</td>\n",
       "      <td>19.405069</td>\n",
       "      <td>21.568836</td>\n",
       "      <td>20.189269</td>\n",
       "      <td>19.131730</td>\n",
       "      <td>17.915217</td>\n",
       "      <td>19.506041</td>\n",
       "      <td>16.973474</td>\n",
       "      <td>18.954116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  20854.000000  20854.000000  20854.000000  20854.000000  20854.000000   \n",
       "mean      55.946885     51.186513     58.790715     63.548063     50.059329   \n",
       "std       15.846184     17.353144     13.560364     12.541247     16.577858   \n",
       "min        6.000000      5.000000     10.000000     15.000000      5.000000   \n",
       "25%       46.000000     39.000000     51.000000     58.000000     35.000000   \n",
       "50%       58.000000     53.000000     61.000000     65.000000     53.000000   \n",
       "75%       68.000000     66.000000     67.000000     72.000000     63.000000   \n",
       "max       84.000000     82.000000     90.000000     85.000000     81.000000   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  20854.000000  20854.000000  20854.000000  20854.000000  20854.000000   \n",
       "mean      17.920492     13.673587     14.056053     36.904766     39.794428   \n",
       "std       18.497045     11.288914     12.213878     12.595262     14.124485   \n",
       "min        2.000000      2.000000      2.000000     19.000000     18.000000   \n",
       "25%        7.000000      8.000000      8.000000     28.000000     31.000000   \n",
       "50%       11.000000     11.000000     11.000000     34.000000     32.000000   \n",
       "75%       14.000000     14.000000     14.000000     37.000000     59.000000   \n",
       "max       79.000000     72.000000     78.000000     67.000000     61.000000   \n",
       "\n",
       "           ...                 31            32            33            34  \\\n",
       "count      ...       20854.000000  20854.000000  20854.000000  20854.000000   \n",
       "mean       ...          45.481538     54.945478     42.496643     38.513139   \n",
       "std        ...           7.814612      8.086104     19.405069     21.568836   \n",
       "min        ...          16.000000     40.000000     12.000000     11.000000   \n",
       "25%        ...          42.000000     48.000000     20.000000     14.000000   \n",
       "50%        ...          47.000000     61.000000     55.000000     34.000000   \n",
       "75%        ...          47.000000     62.000000     57.000000     60.000000   \n",
       "max        ...          63.000000     64.000000     62.000000     64.000000   \n",
       "\n",
       "                 35            36            37            38            39  \\\n",
       "count  20854.000000  20854.000000  20854.000000  20854.000000  20854.000000   \n",
       "mean      38.419344     14.767287     13.279179     20.379591     17.112544   \n",
       "std       20.189269     19.131730     17.915217     19.506041     16.973474   \n",
       "min       11.000000      7.000000      5.000000     14.000000      7.000000   \n",
       "25%       18.000000      7.000000      5.000000     14.000000      7.000000   \n",
       "50%       41.000000      8.000000      6.000000     14.000000     13.000000   \n",
       "75%       58.000000     11.000000     13.000000     15.000000     14.000000   \n",
       "max       60.000000     75.000000     69.000000     82.000000     70.000000   \n",
       "\n",
       "                 40  \n",
       "count  20854.000000  \n",
       "mean      15.774911  \n",
       "std       18.954116  \n",
       "min        6.000000  \n",
       "25%        6.000000  \n",
       "50%       12.000000  \n",
       "75%       13.000000  \n",
       "max       75.000000  \n",
       "\n",
       "[8 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Check if data is Gaussian distribution </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not normal distribution\n"
     ]
    }
   ],
   "source": [
    "z,pval = mstats.normaltest(df)\n",
    "\n",
    "#Using the confidence value as 95% \n",
    "if(pval.all() < 0.05):\n",
    "    print('Not normal distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Why to use Min-Max Scalar?</b>\n",
    "<br>\n",
    "<br>\n",
    "-- As data is not normally distributed we cannot use <b>StandardScalar</b>.<br>\n",
    "-- <b>Min-Max Scalar</b> works better if the distribution is not Gaussian or if the standard deviation is very small.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = MinMaxScaler()\n",
    "scalar.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53846154, 0.35064935, 0.4625    , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.35897436, 0.20779221, 0.9       , ..., 0.        , 0.0952381 ,\n",
       "        0.08695652],\n",
       "       [0.5       , 0.37662338, 0.55      , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.64102564, 0.19480519, 0.7125    , ..., 0.        , 0.0952381 ,\n",
       "        0.08695652],\n",
       "       [0.53846154, 0.87012987, 0.6875    , ..., 0.01470588, 0.11111111,\n",
       "        0.10144928],\n",
       "       [0.75641026, 0.88311688, 0.6875    , ..., 0.01470588, 0.11111111,\n",
       "        0.10144928]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data = scalar.transform(df)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dimensionality Reduction using PCA</b>\n",
    "<br>\n",
    "PCA is applied to take the necessary attributes that are representative of the variance of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4740565350106719\n",
      "0.7079832514318333\n",
      "0.8175816601205612\n",
      "0.8655186382785133\n",
      "0.9046341748038949\n",
      "0.9249495743049728\n",
      "0.9413642290762874\n",
      "0.955211231934536\n",
      "0.9645962642818509\n",
      "0.9738063097105232\n",
      "0.9791376165338971\n",
      "0.9828728359055369\n",
      "0.9863682391333966\n",
      "0.9894399321665592\n",
      "0.991859622019979\n",
      "0.9939920558446469\n",
      "0.9959087742588518\n",
      "0.997412299246496\n",
      "0.9981635830033067\n",
      "0.9987693521850495\n",
      "0.9991801677019031\n",
      "0.9995150963622441\n",
      "0.9997481069037992\n",
      "0.9998864458476638\n",
      "0.9999573507143993\n",
      "0.9999821657957485\n",
      "0.9999926929921165\n",
      "0.9999999999999989\n",
      "0.9999999999999986\n",
      "0.9999999999999996\n",
      "0.9999999999999994\n",
      "0.9999999999999993\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, df.shape[1]+1):\n",
    "    pca = PCA(n_components=i)\n",
    "    pca.fit(scaled_data)\n",
    "    print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore after applying PCA we can see that <b>15 variable are capturing approximately 99% of the variance.</b>\n",
    "<br>\n",
    "Hence we are considering 15 features for our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=15)\n",
    "pca.fit(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pca = pca.transform(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20854, 41)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20854, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are spliting data into training and testing data. 80% of the data is taken for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will apply all the algorithms one by one on training and testing data and see the outcome using accuracy as the performance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. Decision Tree</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5602972908175498\n"
     ]
    }
   ],
   "source": [
    "predicted= clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2. Random Forest</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5662910573004076\n"
     ]
    }
   ],
   "source": [
    "predicted= clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3. K Nearset Neighbour</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5348837209302325\n"
     ]
    }
   ],
   "source": [
    "predicted= clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>4. Naive Bayes Classifier</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=BernoulliNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5648525533445217\n"
     ]
    }
   ],
   "source": [
    "predicted= clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>5. Support Vector Machines</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=SVC(gamma='auto')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5504675137856629\n"
     ]
    }
   ],
   "source": [
    "predicted= clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>6. Logistic Regression</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='lbfgs')\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6008151522416687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.58      0.56      1815\n",
      "           1       0.66      0.61      0.63      2356\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      4171\n",
      "   macro avg       0.60      0.60      0.60      4171\n",
      "weighted avg       0.61      0.60      0.60      4171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted=logreg.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, predicted)) \n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Conclusion </b><br>\n",
    "    As we can see that the accuracy of <b> Logistic Regression </b> is the highest. Hence we should use Logistic Regression for doing predictions on this data set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
